
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Unsloth: Continued Pretraining &#8212; Hands-On AI</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'llm/unsloth_manifesto';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="Hands-On AI - Home"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="Hands-On AI - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Experimental AI Lab
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../image_generation_embeddings/image_generation_embeddings.html">Image generation &amp; Embeddings</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../image_generation_embeddings/image_generation_intro.html">Intro: The “Undersurface”</a></li>
<li class="toctree-l2"><a class="reference internal" href="../image_generation_embeddings/image_generation_comfyui.html">ComfyUI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../image_generation_embeddings/image_generation_context.html">Text-To-Image Context</a></li>
<li class="toctree-l2"><a class="reference internal" href="../image_generation_embeddings/image_generation_scoring.html">Scoring</a></li>
<li class="toctree-l2"><a class="reference internal" href="../image_generation_embeddings/image_generation_prompting.html">Prompting</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="llm_intro.html">LLMs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="ollama_start.html">Ollama</a></li>
<li class="toctree-l2"><a class="reference internal" href="unsloth_dreams.html">Finetuning with unsloth: Ten Thousand Dreams</a></li>
<li class="toctree-l2"><a class="reference internal" href="ollama_adapter.html">Ollama Modelfile with Adapter</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataset_dreams.html">Dataset: Ten Thousand Dreams</a></li>
<li class="toctree-l2"><a class="reference internal" href="dataset_beer.html">Dataset: BeerBot</a></li>
<li class="toctree-l2"><a class="reference internal" href="unsloth_beer.html">Finetuning with unsloth: BeerBot</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../interface/interface_intro.html">Interface</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../interface/ollama_ui_dreams.html">Interface: Dream Interpreter (with ollama-ui)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../imgtotext/intro.html">Image(s) to Text</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../imgtotext/codesamples.html">Code Samples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../imgtotext/visiontext.html">Vision to Text</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../video/video_input_artworks.html">Video (Live Input) Artworks</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/attributeerror39/Hands-On-AI" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/attributeerror39/Hands-On-AI/issues/new?title=Issue%20on%20page%20%2Fllm/unsloth_manifesto.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/llm/unsloth_manifesto.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Unsloth: Continued Pretraining</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unsloth">Unsloth</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-completion-raw-text-training">Text Completion / Raw Text Training</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-prep">Data Prep</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-data">Custom data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continued-pretraining">Continued Pretraining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">Inference</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="unsloth-continued-pretraining">
<h1>Unsloth: Continued Pretraining<a class="headerlink" href="#unsloth-continued-pretraining" title="Link to this heading">#</a></h1>
<p>Source: <a class="reference external" href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_(7B)-Text_Completion.ipynb">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_(7B)-Text_Completion.ipynb</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>unsloth<span class="w"> </span>tf-keras
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span><span class="s1">&#39;optree&gt;=0.13.0&#39;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting unsloth
  Using cached unsloth-2025.3.19-py3-none-any.whl.metadata (46 kB)
Collecting tf-keras
  Using cached tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)
Collecting unsloth_zoo&gt;=2025.3.17 (from unsloth)
  Using cached unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)
Collecting torch&gt;=2.4.0 (from unsloth)
  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)
Collecting xformers&gt;=0.0.27.post2 (from unsloth)
  Using cached xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)
Collecting bitsandbytes (from unsloth)
  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)
Collecting triton&gt;=3.0.0 (from unsloth)
  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)
Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from unsloth) (24.1)
Collecting tyro (from unsloth)
  Using cached tyro-0.9.18-py3-none-any.whl.metadata (9.2 kB)
Collecting transformers!=4.47.0,&gt;=4.46.1 (from unsloth)
  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)
Collecting datasets&gt;=2.16.0 (from unsloth)
  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)
Collecting sentencepiece&gt;=0.2.0 (from unsloth)
  Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from unsloth) (4.66.5)
Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from unsloth) (6.0.0)
Requirement already satisfied: wheel&gt;=0.42.0 in /opt/conda/lib/python3.11/site-packages (from unsloth) (0.44.0)
Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from unsloth) (1.26.4)
Collecting accelerate&gt;=0.34.1 (from unsloth)
  Using cached accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)
Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,&lt;=0.15.2,&gt;=0.7.9 (from unsloth)
  Using cached trl-0.15.2-py3-none-any.whl.metadata (11 kB)
Collecting peft!=0.11.0,&gt;=0.7.1 (from unsloth)
  Using cached peft-0.15.1-py3-none-any.whl.metadata (13 kB)
Collecting protobuf&lt;4.0.0 (from unsloth)
  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)
Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (from unsloth) (0.23.5)
Collecting hf_transfer (from unsloth)
  Using cached hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)
Collecting diffusers (from unsloth)
  Using cached diffusers-0.32.2-py3-none-any.whl.metadata (18 kB)
Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from unsloth) (0.18.0)
Collecting tensorflow&lt;2.20,&gt;=2.19 (from tf-keras)
  Using cached tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)
Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate&gt;=0.34.1-&gt;unsloth) (6.0.2)
Collecting safetensors&gt;=0.4.3 (from accelerate&gt;=0.34.1-&gt;unsloth)
  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)
Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets&gt;=2.16.0-&gt;unsloth) (3.16.1)
Collecting pyarrow&gt;=15.0.0 (from datasets&gt;=2.16.0-&gt;unsloth)
  Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)
Collecting dill&lt;0.3.9,&gt;=0.3.0 (from datasets&gt;=2.16.0-&gt;unsloth)
  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)
Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets&gt;=2.16.0-&gt;unsloth) (2.2.3)
Requirement already satisfied: requests&gt;=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets&gt;=2.16.0-&gt;unsloth) (2.32.3)
Collecting xxhash (from datasets&gt;=2.16.0-&gt;unsloth)
  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multiprocess&lt;0.70.17 (from datasets&gt;=2.16.0-&gt;unsloth)
  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)
Requirement already satisfied: fsspec&lt;=2024.12.0,&gt;=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]&lt;=2024.12.0,&gt;=2023.1.0-&gt;datasets&gt;=2.16.0-&gt;unsloth) (2024.9.0)
Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets&gt;=2.16.0-&gt;unsloth) (3.10.8)
Collecting huggingface_hub (from unsloth)
  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub-&gt;unsloth) (4.12.2)
Requirement already satisfied: absl-py&gt;=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (2.1.0)
Requirement already satisfied: astunparse&gt;=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (1.6.3)
Requirement already satisfied: flatbuffers&gt;=24.3.25 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (24.3.25)
Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,&gt;=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (0.6.0)
Requirement already satisfied: google-pasta&gt;=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (0.2.0)
Requirement already satisfied: libclang&gt;=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (18.1.1)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (3.4.0)
Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (75.1.0)
Requirement already satisfied: six&gt;=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (1.16.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (2.4.0)
Requirement already satisfied: wrapt&gt;=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (1.16.0)
Requirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (1.66.2)
Collecting tensorboard~=2.19.0 (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras)
  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)
Collecting keras&gt;=3.5.0 (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras)
  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)
Requirement already satisfied: h5py&gt;=3.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (3.12.1)
Collecting ml-dtypes&lt;1.0.0,&gt;=0.5.1 (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras)
  Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)
Requirement already satisfied: tensorflow-io-gcs-filesystem&gt;=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (0.37.1)
Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch&gt;=2.4.0-&gt;unsloth) (3.3)
Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch&gt;=2.4.0-&gt;unsloth) (3.1.4)
Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cublas-cu12==12.4.5.8 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cufft-cu12==11.2.1.3 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-curand-cu12==10.3.5.147 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparselt-cu12==0.6.2 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting nvidia-nccl-cu12==2.21.5 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvtx-cu12==12.4.127 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting sympy==1.13.1 (from torch&gt;=2.4.0-&gt;unsloth)
  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1-&gt;torch&gt;=2.4.0-&gt;unsloth) (1.3.0)
Collecting regex!=2019.12.17 (from transformers!=4.47.0,&gt;=4.46.1-&gt;unsloth)
  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)
Collecting tokenizers&lt;0.22,&gt;=0.21 (from transformers!=4.47.0,&gt;=4.46.1-&gt;unsloth)
  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,&lt;=0.15.2,&gt;=0.7.9-&gt;unsloth) (13.9.1)
Collecting cut_cross_entropy (from unsloth_zoo&gt;=2025.3.17-&gt;unsloth)
  Using cached cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)
Requirement already satisfied: pillow in /opt/conda/lib/python3.11/site-packages (from unsloth_zoo&gt;=2025.3.17-&gt;unsloth) (10.4.0)
Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.11/site-packages (from diffusers-&gt;unsloth) (8.5.0)
INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.
Collecting torchvision (from unsloth)
  Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)
Collecting docstring-parser&gt;=0.15 (from tyro-&gt;unsloth)
  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)
Collecting shtab&gt;=1.5.6 (from tyro-&gt;unsloth)
  Using cached shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)
Collecting typeguard&gt;=4.0.0 (from tyro-&gt;unsloth)
  Using cached typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)
Collecting typing-extensions&gt;=3.7.4.3 (from huggingface_hub-&gt;unsloth)
  Using cached typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)
Requirement already satisfied: aiohappyeyeballs&gt;=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.16.0-&gt;unsloth) (2.4.3)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.16.0-&gt;unsloth) (1.3.1)
Requirement already satisfied: attrs&gt;=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.16.0-&gt;unsloth) (24.2.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.16.0-&gt;unsloth) (1.4.1)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.16.0-&gt;unsloth) (6.1.0)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.12.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp-&gt;datasets&gt;=2.16.0-&gt;unsloth) (1.13.1)
Requirement already satisfied: namex in /opt/conda/lib/python3.11/site-packages (from keras&gt;=3.5.0-&gt;tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (0.0.8)
Requirement already satisfied: optree in /opt/conda/lib/python3.11/site-packages (from keras&gt;=3.5.0-&gt;tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (0.12.1)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.11/site-packages (from requests&gt;=2.32.2-&gt;datasets&gt;=2.16.0-&gt;unsloth) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.11/site-packages (from requests&gt;=2.32.2-&gt;datasets&gt;=2.16.0-&gt;unsloth) (3.10)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests&gt;=2.32.2-&gt;datasets&gt;=2.16.0-&gt;unsloth) (2.2.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests&gt;=2.32.2-&gt;datasets&gt;=2.16.0-&gt;unsloth) (2024.8.30)
Requirement already satisfied: markdown-it-py&gt;=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich-&gt;trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,&lt;=0.15.2,&gt;=0.7.9-&gt;unsloth) (3.0.0)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich-&gt;trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,&lt;=0.15.2,&gt;=0.7.9-&gt;unsloth) (2.18.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard~=2.19.0-&gt;tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (3.7)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard~=2.19.0-&gt;tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (0.7.2)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard~=2.19.0-&gt;tensorflow&lt;2.20,&gt;=2.19-&gt;tf-keras) (3.0.4)
Requirement already satisfied: zipp&gt;=3.20 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata-&gt;diffusers-&gt;unsloth) (3.20.2)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2-&gt;torch&gt;=2.4.0-&gt;unsloth) (2.1.5)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas-&gt;datasets&gt;=2.16.0-&gt;unsloth) (2.9.0)
Requirement already satisfied: pytz&gt;=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas-&gt;datasets&gt;=2.16.0-&gt;unsloth) (2024.2)
Requirement already satisfied: tzdata&gt;=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas-&gt;datasets&gt;=2.16.0-&gt;unsloth) (2024.2)
Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,&lt;=0.15.2,&gt;=0.7.9-&gt;unsloth) (0.1.2)
Using cached unsloth-2025.3.19-py3-none-any.whl (192 kB)
Using cached tf_keras-2.19.0-py3-none-any.whl (1.7 MB)
Using cached accelerate-1.6.0-py3-none-any.whl (354 kB)
Using cached datasets-3.5.0-py3-none-any.whl (491 kB)
Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)
Using cached peft-0.15.1-py3-none-any.whl (411 kB)
Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)
Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
Using cached tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)
Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)
Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)
Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)
Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)
Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)
Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)
Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)
Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)
Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)
Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)
Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)
Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)
Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)
Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)
Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)
Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)
Downloading transformers-4.51.1-py3-none-any.whl (10.4 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">10.4/10.4 MB</span> <span class=" -Color -Color-Red">37.5 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>00:01
?25hUsing cached trl-0.15.2-py3-none-any.whl (318 kB)
Using cached unsloth_zoo-2025.3.17-py3-none-any.whl (127 kB)
Using cached xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)
Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">76.1/76.1 MB</span> <span class=" -Color -Color-Red">47.8 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>00:0100:01m
?25hUsing cached diffusers-0.32.2-py3-none-any.whl (3.2 MB)
Using cached hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)
Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)
Using cached tyro-0.9.18-py3-none-any.whl (123 kB)
Using cached dill-0.3.8-py3-none-any.whl (116 kB)
Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)
Using cached keras-3.9.2-py3-none-any.whl (1.3 MB)
Using cached ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)
Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)
Using cached pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)
Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)
Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)
Using cached shtab-1.7.1-py3-none-any.whl (14 kB)
Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)
Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
Using cached typeguard-4.4.2-py3-none-any.whl (35 kB)
Using cached typing_extensions-4.13.1-py3-none-any.whl (45 kB)
Using cached cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)
Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)
Installing collected packages: triton, sentencepiece, nvidia-cusparselt-cu12, xxhash, typing-extensions, sympy, shtab, safetensors, regex, pyarrow, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, hf_transfer, docstring-parser, dill, typeguard, tensorboard, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface_hub, tyro, tokenizers, nvidia-cusolver-cu12, keras, diffusers, transformers, torch, tensorflow, datasets, xformers, torchvision, tf-keras, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth
  Attempting uninstall: triton
    Found existing installation: triton 2.3.0
    Uninstalling triton-2.3.0:
      Successfully uninstalled triton-2.3.0
  Attempting uninstall: typing-extensions
    Found existing installation: typing_extensions 4.12.2
    Uninstalling typing_extensions-4.12.2:
      Successfully uninstalled typing_extensions-4.12.2
  Attempting uninstall: sympy
    Found existing installation: sympy 1.13.3
    Uninstalling sympy-1.13.3:
      Successfully uninstalled sympy-1.13.3
  Attempting uninstall: protobuf
    Found existing installation: protobuf 4.25.5
    Uninstalling protobuf-4.25.5:
      Successfully uninstalled protobuf-4.25.5
  Attempting uninstall: nvidia-nvtx-cu12
    Found existing installation: nvidia-nvtx-cu12 12.1.105
    Uninstalling nvidia-nvtx-cu12-12.1.105:
      Successfully uninstalled nvidia-nvtx-cu12-12.1.105
  Attempting uninstall: nvidia-nvjitlink-cu12
    Found existing installation: nvidia-nvjitlink-cu12 12.6.68
    Uninstalling nvidia-nvjitlink-cu12-12.6.68:
      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.68
  Attempting uninstall: nvidia-nccl-cu12
    Found existing installation: nvidia-nccl-cu12 2.20.5
    Uninstalling nvidia-nccl-cu12-2.20.5:
      Successfully uninstalled nvidia-nccl-cu12-2.20.5
  Attempting uninstall: nvidia-curand-cu12
    Found existing installation: nvidia-curand-cu12 10.3.2.106
    Uninstalling nvidia-curand-cu12-10.3.2.106:
      Successfully uninstalled nvidia-curand-cu12-10.3.2.106
  Attempting uninstall: nvidia-cufft-cu12
    Found existing installation: nvidia-cufft-cu12 11.0.2.54
    Uninstalling nvidia-cufft-cu12-11.0.2.54:
      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54
  Attempting uninstall: nvidia-cuda-runtime-cu12
    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105
    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:
      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105
  Attempting uninstall: nvidia-cuda-nvrtc-cu12
    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105
    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:
      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105
  Attempting uninstall: nvidia-cuda-cupti-cu12
    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105
    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:
      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105
  Attempting uninstall: nvidia-cublas-cu12
    Found existing installation: nvidia-cublas-cu12 12.1.3.1
    Uninstalling nvidia-cublas-cu12-12.1.3.1:
      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1
  Attempting uninstall: ml-dtypes
    Found existing installation: ml-dtypes 0.3.2
    Uninstalling ml-dtypes-0.3.2:
      Successfully uninstalled ml-dtypes-0.3.2
  Attempting uninstall: tensorboard
    Found existing installation: tensorboard 2.16.2
    Uninstalling tensorboard-2.16.2:
      Successfully uninstalled tensorboard-2.16.2
  Attempting uninstall: nvidia-cusparse-cu12
    Found existing installation: nvidia-cusparse-cu12 12.1.0.106
    Uninstalling nvidia-cusparse-cu12-12.1.0.106:
      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106
  Attempting uninstall: nvidia-cudnn-cu12
    Found existing installation: nvidia-cudnn-cu12 8.9.2.26
    Uninstalling nvidia-cudnn-cu12-8.9.2.26:
      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26
  Attempting uninstall: huggingface_hub
    Found existing installation: huggingface-hub 0.23.5
    Uninstalling huggingface-hub-0.23.5:
      Successfully uninstalled huggingface-hub-0.23.5
  Attempting uninstall: nvidia-cusolver-cu12
    Found existing installation: nvidia-cusolver-cu12 11.4.5.107
    Uninstalling nvidia-cusolver-cu12-11.4.5.107:
      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107
  Attempting uninstall: keras
    Found existing installation: keras 3.1.1
    Uninstalling keras-3.1.1:
      Successfully uninstalled keras-3.1.1
  Attempting uninstall: torch
    Found existing installation: torch 2.3.0
    Uninstalling torch-2.3.0:
      Successfully uninstalled torch-2.3.0
  Attempting uninstall: tensorflow
    Found existing installation: tensorflow 2.16.1
    Uninstalling tensorflow-2.16.1:
      Successfully uninstalled tensorflow-2.16.1
  Attempting uninstall: torchvision
    Found existing installation: torchvision 0.18.0
    Uninstalling torchvision-0.18.0:
      Successfully uninstalled torchvision-0.18.0
<span class=" -Color -Color-Red">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span>
<span class=" -Color -Color-Red">zoomaker 0.9.0 requires huggingface-hub&lt;0.24.0,&gt;=0.23.0, but you have huggingface-hub 0.30.2 which is incompatible.</span>
<span class=" -Color -Color-Red">torchaudio 2.3.0 requires torch==2.3.0, but you have torch 2.6.0 which is incompatible.</span>
Successfully installed accelerate-1.6.0 bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 datasets-3.5.0 diffusers-0.32.2 dill-0.3.8 docstring-parser-0.16 hf_transfer-0.1.9 huggingface_hub-0.30.2 keras-3.9.2 ml-dtypes-0.5.1 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 peft-0.15.1 protobuf-3.20.3 pyarrow-19.0.1 regex-2024.11.6 safetensors-0.5.3 sentencepiece-0.2.0 shtab-1.7.1 sympy-1.13.1 tensorboard-2.19.0 tensorflow-2.19.0 tf-keras-2.19.0 tokenizers-0.21.1 torch-2.6.0 torchvision-0.21.0 transformers-4.51.1 triton-3.2.0 trl-0.15.2 typeguard-4.4.2 typing-extensions-4.13.1 tyro-0.9.18 unsloth-2025.3.19 unsloth_zoo-2025.3.17 xformers-0.0.29.post3 xxhash-3.5.0
</pre></div>
</div>
</div>
</div>
<section id="unsloth">
<h2>Unsloth<a class="headerlink" href="#unsloth" title="Link to this heading">#</a></h2>
<section id="text-completion-raw-text-training">
<h3>Text Completion / Raw Text Training<a class="headerlink" href="#text-completion-raw-text-training" title="Link to this heading">#</a></h3>
<p>This is a community notebook collaboration with [Mithex].</p>
<p>We train on <code class="docutils literal notranslate"><span class="pre">Tiny</span> <span class="pre">Stories</span></code> (link <a class="reference external" href="https://huggingface.co/datasets/roneneldan/TinyStories">here</a>) which is a collection of small stories. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Once</span> <span class="n">upon</span> <span class="n">a</span> <span class="n">time</span><span class="p">,</span> <span class="n">there</span> <span class="n">was</span> <span class="n">a</span> <span class="n">little</span> <span class="n">car</span> <span class="n">named</span> <span class="n">Beep</span><span class="o">.</span> <span class="n">Beep</span> <span class="n">loved</span> <span class="n">to</span> <span class="n">go</span> <span class="n">fast</span> <span class="ow">and</span> <span class="n">play</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">sun</span><span class="o">.</span>
<span class="n">Beep</span> <span class="n">was</span> <span class="n">a</span> <span class="n">healthy</span> <span class="n">car</span> <span class="n">because</span> <span class="n">he</span> <span class="n">always</span> <span class="n">had</span> <span class="n">good</span> <span class="n">fuel</span><span class="o">....</span>
</pre></div>
</div>
<p>Instead of <code class="docutils literal notranslate"><span class="pre">Alpaca</span></code>’s Question Answer format, one only needs 1 column - the <code class="docutils literal notranslate"><span class="pre">&quot;text&quot;</span></code> column. This means you can finetune on any dataset and let your model act as a text completion model, like for novel writing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">FastLanguageModel</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="n">max_seq_length</span> <span class="o">=</span> <span class="mi">2048</span> <span class="c1"># Choose any! We auto support RoPE Scaling internally!</span>
<span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+</span>
<span class="n">load_in_4bit</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Use 4bit quantization to reduce memory usage. Can be False.</span>

<span class="c1"># 4bit pre quantized models we support for 4x faster downloading + no OOMs.</span>
<span class="n">fourbit_models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;unsloth/mistral-7b-v0.3-bnb-4bit&quot;</span><span class="p">,</span>      <span class="c1"># New Mistral v3 2x faster!</span>
    <span class="s2">&quot;unsloth/mistral-7b-instruct-v0.3-bnb-4bit&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unsloth/llama-3-8b-bnb-4bit&quot;</span><span class="p">,</span>           <span class="c1"># Llama-3 15 trillion tokens model 2x faster!</span>
    <span class="s2">&quot;unsloth/llama-3-8b-Instruct-bnb-4bit&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unsloth/llama-3-70b-bnb-4bit&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unsloth/Phi-3-mini-4k-instruct&quot;</span><span class="p">,</span>        <span class="c1"># Phi-3 2x faster!</span>
    <span class="s2">&quot;unsloth/Phi-3-medium-4k-instruct&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unsloth/mistral-7b-bnb-4bit&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unsloth/gemma-7b-bnb-4bit&quot;</span><span class="p">,</span>             <span class="c1"># Gemma 2.2x faster!</span>
<span class="p">]</span> <span class="c1"># More models at https://huggingface.co/unsloth</span>

<span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;unsloth/mistral-7b-v0.3&quot;</span><span class="p">,</span> <span class="c1"># &quot;unsloth/mistral-7b&quot; for 16bit loading</span>
    <span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">max_seq_length</span><span class="p">,</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span><span class="p">,</span>
    <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="n">load_in_4bit</span><span class="p">,</span>
    <span class="c1"># token = &quot;hf_...&quot;, # use one if using gated models like meta-llama/Llama-2-7b-hf</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade &#39;optree&gt;=0.13.0&#39;`.
  warnings.warn(
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2025-04-09 11:26:12.998614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1744197973.019786     573 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1744197973.026403     573 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1744197973.044830     573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1744197973.044860     573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1744197973.044862     573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1744197973.044864     573 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-04-09 11:26:13.051657: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unsloth: Failed to patch Gemma3ForConditionalGeneration.
🦥 Unsloth Zoo will now patch everything to make training faster!
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/conda/lib/python3.11/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade &#39;optree&gt;=0.13.0&#39;`.
  warnings.warn(
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==((====))==  Unsloth 2025.3.19: Fast Mistral patching. Transformers: 4.51.1.
   \\   /|    NVIDIA A100-SXM4-80GB MIG 2g.20gb. Num GPUs = 1. Max memory: 19.5 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]
 &quot;-____-&quot;     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
</pre></div>
</div>
</div>
</div>
<p>We now add LoRA adapters so we only need to update 1 to 10% of all parameters!</p>
<p>We also add <code class="docutils literal notranslate"><span class="pre">embed_tokens</span></code> and <code class="docutils literal notranslate"><span class="pre">lm_head</span></code> to allow the model to learn out of distribution data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">get_peft_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">r</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="c1"># Choose any number &gt; 0 ! Suggested 8, 16, 32, 64, 128</span>
    <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span>
                      <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">,</span>

                      <span class="s2">&quot;embed_tokens&quot;</span><span class="p">,</span> <span class="s2">&quot;lm_head&quot;</span><span class="p">,],</span> <span class="c1"># Add for continual pretraining</span>
    <span class="n">lora_alpha</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
    <span class="n">lora_dropout</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># Supports any, but = 0 is optimized</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span>    <span class="c1"># Supports any, but = &quot;none&quot; is optimized</span>
    <span class="c1"># [NEW] &quot;unsloth&quot; uses 30% less VRAM, fits 2x larger batch sizes!</span>
    <span class="n">use_gradient_checkpointing</span> <span class="o">=</span> <span class="s2">&quot;unsloth&quot;</span><span class="p">,</span> <span class="c1"># True or &quot;unsloth&quot; for very long context</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="mi">3407</span><span class="p">,</span>
    <span class="n">use_rslora</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>  <span class="c1"># We support rank stabilized LoRA</span>
    <span class="n">loftq_config</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># And LoftQ</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unsloth: Offloading input_embeddings to disk to save VRAM
Unsloth: Offloading output_embeddings to disk to save VRAM
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unsloth 2025.3.19 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unsloth: Training embed_tokens in mixed precision to save VRAM
Unsloth: Training lm_head in mixed precision to save VRAM
</pre></div>
</div>
</div>
</div>
<p><a name="Data"></a></p>
</section>
</section>
<section id="data-prep">
<h2>Data Prep<a class="headerlink" href="#data-prep" title="Link to this heading">#</a></h2>
<p>We now use the Tiny Stories dataset from <a class="reference external" href="https://huggingface.co/datasets/roneneldan/TinyStories">https://huggingface.co/datasets/roneneldan/TinyStories</a>. We only sample the first 5000 rows to speed training up. We must add <code class="docutils literal notranslate"><span class="pre">EOS_TOKEN</span></code> or <code class="docutils literal notranslate"><span class="pre">tokenizer.eos_token</span></code> or else the model’s generation will go on forever.</p>
<p>If you want to use the <code class="docutils literal notranslate"><span class="pre">llama-3</span></code> template for ShareGPT datasets, try our conversational <a class="reference external" href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_(7B)-Conversational.ipynb">notebook</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;roneneldan/TinyStories&quot;</span><span class="p">,</span> <span class="n">split</span> <span class="o">=</span> <span class="s2">&quot;train[:2500]&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dataset({
    features: [&#39;text&#39;],
    num_rows: 2500
})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;text&#39;: &#39;One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n\nLily went to her mom and said, &quot;Mom, I found this needle. Can you share it with me and sew my shirt?&quot; Her mom smiled and said, &quot;Yes, Lily, we can share the needle and fix your shirt.&quot;\n\nTogether, they shared the needle and sewed the button on Lily\&#39;s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.&#39;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;text&#39;: &#39;Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\n\nOne day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Beep drove under the tree and watched the leaves fall on him. He laughed and beeped his horn.\n\nBeep played with the falling leaves all day. When it was time to go home, Beep knew he needed more fuel. He went to the fuel place and got more healthy fuel. Now, Beep was ready to go fast and play again the next day. And Beep lived happily ever after.&#39;}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;text&#39;: [&#39;One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n\nLily went to her mom and said, &quot;Mom, I found this needle. Can you share it with me and sew my shirt?&quot; Her mom smiled and said, &quot;Yes, Lily, we can share the needle and fix your shirt.&quot;\n\nTogether, they shared the needle and sewed the button on Lily\&#39;s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.&#39;,
  &#39;Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\n\nOne day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Beep drove under the tree and watched the leaves fall on him. He laughed and beeped his horn.\n\nBeep played with the falling leaves all day. When it was time to go home, Beep knew he needed more fuel. He went to the fuel place and got more healthy fuel. Now, Beep was ready to go fast and play again the next day. And Beep lived happily ever after.&#39;,
  &#39;One day, a little fish named Fin was swimming near the shore. He saw a big crab and wanted to be friends. &quot;Hi, I am Fin. Do you want to play?&quot; asked the little fish. The crab looked at Fin and said, &quot;No, I don\&#39;t want to play. I am cold and I don\&#39;t feel fine.&quot;\n\nFin felt sad but wanted to help the crab feel better. He swam away and thought of a plan. He remembered that the sun could make things warm. So, Fin swam to the top of the water and called to the sun, &quot;Please, sun, help my new friend feel fine and not freeze!&quot;\n\nThe sun heard Fin\&#39;s call and shone its warm light on the shore. The crab started to feel better and not so cold. He saw Fin and said, &quot;Thank you, little fish, for making me feel fine. I don\&#39;t feel like I will freeze now. Let\&#39;s play together!&quot; And so, Fin and the crab played and became good friends.&#39;]}
</pre></div>
</div>
</div>
</div>
</section>
<section id="custom-data">
<h2>Custom data<a class="headerlink" href="#custom-data" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;json&#39;</span><span class="p">,</span> <span class="n">data_files</span><span class="o">=</span><span class="s1">&#39;data/manifesto.json&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">dataset</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Dataset({
    features: [&#39;text&#39;],
    num_rows: 314
})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;text&#39;: [&#39;INDUSTRIAL SOCIETY AND ITS FUTURE&#39;,
  &#39;Introduction&#39;,
  &#39;1. The Industrial Revolution and its consequences have been a disaster for the human race. They have greatly increased the life-expectancy of those of us who live in “advanced” countries, but they have destabilized society, have made life unfulfilling, have subjected human beings to indignities, have led to widespread psychological suffering (in the Third World to physical suffering as well) and have inflicted severe damage on the natural world. The continued development of technology will worsen the situation. It will certainly subject human beings to greater indignities and inflict greater damage on the natural world, it will probably lead to greater social disruption and psychological suffering, and it may lead to increased physical suffering even in “advanced” countries.&#39;,
  &#39;2. The industrial-technological system may survive or it may break down. If it survives, it MAY eventually achieve a low level of physical and psychological suffering, but only after passing through a long and very painful period of adjustment and only at the cost of permanently reducing human beings and many other living organisms to engineered products and mere cogs in the social machine. Furthermore, if the system survives, the consequences will be inevitable: There is no way of reforming or modifying the system so as to prevent it from depriving people of dignity and autonomy.&#39;,
  &#39;3. If the system breaks down the consequences will still be very painful. But the bigger the system grows the more disastrous the results of its breakdown will be, so if it is to break down it had best break down sooner rather than later.&#39;]}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">EOS_TOKEN</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
<span class="k">def</span><span class="w"> </span><span class="nf">formatting_prompts_func</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span> <span class="s2">&quot;text&quot;</span> <span class="p">:</span> <span class="p">[</span><span class="n">example</span> <span class="o">+</span> <span class="n">EOS_TOKEN</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]]</span> <span class="p">}</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">formatting_prompts_func</span><span class="p">,</span> <span class="n">batched</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,)</span>
</pre></div>
</div>
</div>
</div>
<p><a name="Train"></a></p>
<section id="continued-pretraining">
<h3>Continued Pretraining<a class="headerlink" href="#continued-pretraining" title="Link to this heading">#</a></h3>
<p>Now let’s use Unsloth’s <code class="docutils literal notranslate"><span class="pre">UnslothTrainer</span></code>! More docs here: <a class="reference external" href="https://huggingface.co/docs/trl/sft_trainer">TRL SFT docs</a>. We do 20 steps to speed things up, but you can set <code class="docutils literal notranslate"><span class="pre">num_train_epochs=1</span></code> for a full run, and turn off <code class="docutils literal notranslate"><span class="pre">max_steps=None</span></code>.</p>
<p>Also set <code class="docutils literal notranslate"><span class="pre">embedding_learning_rate</span></code> to be a learning rate at least 2x or 10x smaller than <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> to make continual pretraining work!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">trl</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTTrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainingArguments</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">is_bfloat16_supported</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">unsloth</span><span class="w"> </span><span class="kn">import</span> <span class="n">UnslothTrainer</span><span class="p">,</span> <span class="n">UnslothTrainingArguments</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">UnslothTrainer</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">,</span>
    <span class="n">dataset_text_field</span> <span class="o">=</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
    <span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">max_seq_length</span><span class="p">,</span>
    <span class="n">dataset_num_proc</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>

    <span class="n">args</span> <span class="o">=</span> <span class="n">UnslothTrainingArguments</span><span class="p">(</span>
        <span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>

        <span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="c1"># num_train_epochs = 1,</span>
        <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">40</span><span class="p">,</span>

        <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">5e-5</span><span class="p">,</span>
        <span class="n">embedding_learning_rate</span> <span class="o">=</span> <span class="mf">5e-6</span><span class="p">,</span>

        <span class="n">fp16</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">is_bfloat16_supported</span><span class="p">(),</span>
        <span class="n">bf16</span> <span class="o">=</span> <span class="n">is_bfloat16_supported</span><span class="p">(),</span>
        <span class="n">logging_steps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">optim</span> <span class="o">=</span> <span class="s2">&quot;adamw_8bit&quot;</span><span class="p">,</span>
        <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.00</span><span class="p">,</span>
        <span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="mi">3407</span><span class="p">,</span>
        <span class="n">output_dir</span> <span class="o">=</span> <span class="s2">&quot;outputs&quot;</span><span class="p">,</span>
        <span class="n">report_to</span> <span class="o">=</span> <span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="c1"># Use this for WandB etc</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Show current memory stats</span>
<span class="n">gpu_stats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">start_gpu_memory</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_reserved</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">max_memory</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">gpu_stats</span><span class="o">.</span><span class="n">total_memory</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GPU = </span><span class="si">{</span><span class="n">gpu_stats</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">. Max memory = </span><span class="si">{</span><span class="n">max_memory</span><span class="si">}</span><span class="s2"> GB.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">start_gpu_memory</span><span class="si">}</span><span class="s2"> GB of memory reserved.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GPU = NVIDIA A100-SXM4-80GB MIG 2g.20gb. Max memory = 19.5 GB.
7.0 GB of memory reserved.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer_stats</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 314 | Num Epochs = 3 | Total steps = 40
O^O/ \_/ \    Batch size per device = 2 | Gradient accumulation steps = 8
\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16
 &quot;-____-&quot;     Trainable parameters = 603,979,776/7,000,000,000 (8.63% trained)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unsloth: Will smartly offload gradients to save VRAM!
</pre></div>
</div>
<div class="output text_html">
    <div>
      
      <progress value='28' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [28/40 02:49 < 01:18, 0.15 it/s, Epoch 1.41/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
 <tr style="text-align: left;">
      <th>Step</th>
      <th>Training Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>2.242300</td>
    </tr>
    <tr>
      <td>2</td>
      <td>2.333300</td>
    </tr>
    <tr>
      <td>3</td>
      <td>2.275800</td>
    </tr>
    <tr>
      <td>4</td>
      <td>2.156400</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.999200</td>
    </tr>
    <tr>
      <td>6</td>
      <td>2.135800</td>
    </tr>
    <tr>
      <td>7</td>
      <td>2.088700</td>
    </tr>
    <tr>
      <td>8</td>
      <td>2.019800</td>
    </tr>
    <tr>
      <td>9</td>
      <td>2.090900</td>
    </tr>
    <tr>
      <td>10</td>
      <td>1.983000</td>
    </tr>
    <tr>
      <td>11</td>
      <td>2.104900</td>
    </tr>
    <tr>
      <td>12</td>
      <td>2.035300</td>
    </tr>
    <tr>
      <td>13</td>
      <td>2.068700</td>
    </tr>
    <tr>
      <td>14</td>
      <td>1.946300</td>
    </tr>
    <tr>
      <td>15</td>
      <td>1.965600</td>
    </tr>
    <tr>
      <td>16</td>
      <td>2.066200</td>
    </tr>
    <tr>
      <td>17</td>
      <td>2.028500</td>
    </tr>
    <tr>
      <td>18</td>
      <td>1.936300</td>
    </tr>
    <tr>
      <td>19</td>
      <td>1.912900</td>
    </tr>
    <tr>
      <td>20</td>
      <td>3.156900</td>
    </tr>
    <tr>
      <td>21</td>
      <td>1.064100</td>
    </tr>
    <tr>
      <td>22</td>
      <td>1.185300</td>
    </tr>
    <tr>
      <td>23</td>
      <td>1.003000</td>
    </tr>
    <tr>
      <td>24</td>
      <td>1.014100</td>
    </tr>
    <tr>
      <td>25</td>
      <td>1.093100</td>
    </tr>
    <tr>
      <td>26</td>
      <td>0.984600</td>
    </tr>
  </tbody>
</table><p></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Show final memory and time stats</span>
<span class="n">used_memory</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_reserved</span><span class="p">()</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span> <span class="o">/</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">used_memory_for_lora</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">used_memory</span> <span class="o">-</span> <span class="n">start_gpu_memory</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">used_percentage</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">used_memory</span> <span class="o">/</span> <span class="n">max_memory</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">lora_percentage</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">used_memory_for_lora</span> <span class="o">/</span> <span class="n">max_memory</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">trainer_stats</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;train_runtime&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> seconds used for training.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">trainer_stats</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;train_runtime&#39;</span><span class="p">]</span><span class="o">/</span><span class="mi">60</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2"> minutes used for training.&quot;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak reserved memory = </span><span class="si">{</span><span class="n">used_memory</span><span class="si">}</span><span class="s2"> GB.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak reserved memory for training = </span><span class="si">{</span><span class="n">used_memory_for_lora</span><span class="si">}</span><span class="s2"> GB.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak reserved memory % of max memory = </span><span class="si">{</span><span class="n">used_percentage</span><span class="si">}</span><span class="s2"> %.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Peak reserved memory for training % of max memory = </span><span class="si">{</span><span class="n">lora_percentage</span><span class="si">}</span><span class="s2"> %.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2780.9282 seconds used for training.
46.35 minutes used for training.
Peak reserved memory = 11.432 GB.
Peak reserved memory for training = 5.065 GB.
Peak reserved memory % of max memory = 77.516 %.
Peak reserved memory for training % of max memory = 34.344 %.
</pre></div>
</div>
</div>
</div>
<p><a name="Inference"></a></p>
</section>
<section id="inference">
<h3>Inference<a class="headerlink" href="#inference" title="Link to this heading">#</a></h3>
<p>Let’s run the model!</p>
<p>We first will try to see if the model follows the style and understands to write a story that is within the distribution of “Tiny Stories”. Ie a story fit for a bed time story most likely.</p>
<p>We select “Once upon a time, in a galaxy, far far away,” since it normally is associated with Star Wars.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">TextIteratorStreamer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">threading</span><span class="w"> </span><span class="kn">import</span> <span class="n">Thread</span>
<span class="n">text_streamer</span> <span class="o">=</span> <span class="n">TextIteratorStreamer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">textwrap</span>
<span class="n">max_print_width</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Before running inference, call `FastLanguageModel.for_inference` first</span>

<span class="n">FastLanguageModel</span><span class="o">.</span><span class="n">for_inference</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
<span class="p">[</span>
    <span class="s2">&quot;Once upon a time, in a galaxy, far far away,&quot;</span>
<span class="p">]</span><span class="o">*</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_tensors</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">generation_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">streamer</span> <span class="o">=</span> <span class="n">text_streamer</span><span class="p">,</span>
    <span class="n">max_new_tokens</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
    <span class="n">use_cache</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">thread</span> <span class="o">=</span> <span class="n">Thread</span><span class="p">(</span><span class="n">target</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n">generation_kwargs</span><span class="p">)</span>
<span class="n">thread</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

<span class="n">length</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">new_text</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">text_streamer</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">wrapped_text</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="n">new_text</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">max_print_width</span><span class="p">)</span>
        <span class="n">length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">wrapped_text</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">wrapped_text</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">wrapped_text</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">wrapped_text</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">length</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">new_text</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">length</span> <span class="o">&gt;=</span> <span class="n">max_print_width</span><span class="p">:</span>
            <span class="n">length</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="nb">print</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">new_text</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">pass</span>
<span class="k">pass</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;s&gt;Once upon a time, in a galaxy, far faraway, there was a little girl named Lily. She loved to 
play with her toys and explore the universe. One day, she found a big, shiny rock. She picked it up and 
put it in her pocket.

Lily went to play with her friends, but she forgot about the rock. When she 
came back home, she realized that she had lost the rock. She was very sad and started to cry.

Her mom 
saw her crying and asked her what was wrong. Lily told her about the rock and how she lost it. Her mom 
said, &quot;Don&#39;t worry, we can find it again.&quot; They went back to the place where Lily found the rock and 
searched for it. After a while, they found the rock and Lily was very happy. She learned that it&#39;s 
important to take care of her things and not to lose them. The end.&lt;/s&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-base-py"
        },
        kernelOptions: {
            name: "conda-base-py",
            path: "./llm"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-base-py'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unsloth">Unsloth</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#text-completion-raw-text-training">Text Completion / Raw Text Training</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-prep">Data Prep</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-data">Custom data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continued-pretraining">Continued Pretraining</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">Inference</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By KI-Lab hfg Offenbach
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>